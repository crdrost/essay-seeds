# Some new sorts of fallacies

## Permissive fallacy
This is a form of affirming the consequent (i.e. mistaking "if" for "only if")
which comes about when people tell you what is permissible or "allowed" and you
interpret it with an air of inevitability.

If I tell you "Santa only gives presents to children who have been good," I have
told you something about the permissible actions for Santa. For some reason
people have no trouble rephrasing this incorrectly as "If a child has been good,
that child will get a present from Santa." That is an incorrect phrasing:
perhaps the child is Jewish, or lives in Morocco, or otherwise falls into the
exceptional cases of good children who do not get presents from Santa. We never
said that Santa gives presents to *every* child who has been good; just that
Santa *only* gives presents to children who have been good.

I like to think of it in terms of arrows. If we were writing what is permissible
we would write the arrows as "good child → gets present." That is one phrasing
of what Robot Santa is allowed to do; we might phrase further rules as "no
presents to Jewish children" or "no present → Jewish child." These arrows are
all *causally ordered* but they are not *logically ordered*: the actual
inference in both cases is "gets present → good child" and "Jewish child → no
present"; those are the actual deductions you are allowed to make.

# No-chance fallacy
As a reasonable person with scientific training I approach the global warming
debate with a sort of trusting skepticism: as far as I can tell the measurements
are being properly carried out and the interpretation of global warming as
caused by humans seems to be pretty well-analyzed and solidly conducted: this is
the "trusting" aspect. At the same time there are many things which people seem
to assume which are never convincingly demonstrated -- for example, that "caused
by humans" means "reversible by humans" or that "this is an ecological
catastrophe waiting to happen" -- and I am much more skeptical of those things.

In the face of this, I want to call attention to a video which went viral,
achieving millions of views on YouTube and elsewhere, titled "The Most
Terrifying Video You'll Ever See." The presenter of the argument insists that
you don't need to know whether global warming is true or not true, because you
can just admit the possibility, whatever else, that you're wrong. Since you're
not infallible, he recommends that you list your options, write down the worst-
case scenarios for each if you're wrong, and then choose which worst-case
scenario you would most wish to face. So if we don't take action on global
warming, the worst-case scenario is the end of the world as we know it; if we do
take action, the worst-case scenario is a global economic crisis, and clearly an
economic crisis is better for us than the end of the world. And it's simply
*wrong*, even though this guy has posted several videos where he claims that he
has not heard anybody yet "poke a hole in the argument." But you simply can't
evaluate a cost rationally without knowing what the actual chance is of
incurring that cost.

I will give you the extreme version of the above argument, so it's obvious that
it's a fallacy of thought. Of course, you know me to be a decent and civilized
and reasonable person, but the question as phrased above is: admit that you
might be wrong. Of course, you probably aren't, but the whole point is that we
need to throw away probabilities. The actions, we'll say, are giving me a
thousand dollars. Now, if you give me a thousand dollars then in the worst case
scenario, you are out of a thousand dollars and I spend it all on things you
disagree with. But if you don't give me a thousand dollars, then in the worst
case scenario I am secretly not a decent and civilized person but instead some
sort of twisted psychopath who will torture you to death and then steal all your
money anyways. Clearly you should give me a thousand dollars even though you are
almost certain that I am a reasonable person, because you *might* be wrong with
*whatever* little probability.

You can see more precisely what the fallacy is, which is that there is an
implicit calculation of probability even in writing down what the worst-case
scenario is. The worst-case scenario for the carbon tax is not a global economic
depression; that is some scenario which falls above some implicit probability
threshold. If you let me dip below that threshold, the worst case scenario is
that the world becomes so tense after an obviously failing and economically
taxing solution that widespread warfare breaks out, which quickly turns nuclear,
which irradiates most of the planet and causes a nuclear winter far worse than
the proposed worst-case warming scenario. Or perhaps, at least, the worst case
is that we spend all of this money to solve global warming and we simply don't
make even the slightest dent in it; due to bureaucratic waste our money simply
gets pocketed by big companies while the world does not reduce its carbon
emissions and we spiral into the same hellscape proposed for the inaction
scenario, except in this one greedy corporations persevere while more good
intentioned citizens die.

If you give my imagination leave to compute a cost, it can compute plausible-
sounding stories of unimaginable horror. For any dichotomy, what is the worst
case scenario? It's quite simple, really: the worst-case scenario is always that
your action wakes up sleeping Cthulhu out of his home in R'lyeh to bring madness
to the human race before he eats us; your only hope is that you are one of the
first who is eaten. What, you don't think it will happen? I don't either. And
you know what really doesn't convince me? if go back to this argument and ask
this supposedly-critical question, *What if you're wrong?*

This is the no-chance fallacy: no discussion of chance is admitted. It has been
a fallacy since Blaise Pascal offered his famous wager, where one choose to be
faithful not out of a sincere belief, but out of fear of an omniscient
judgmental God's punishment: totally neglecting the low probability, for
example, that such an omniscient judgmental God will not also punish you for the
insincerity of your belief and the "me, me, me" attitude one is taken when one
calculates faith in this way.
 
## No-cost fallacy
It's even more prevalent that people regard failure, of whatever probability, as
an unacceptably bad thing. Rather than minimizing the cost of "the worst that
could happen", a lot of people seem to make the opposite choice and try to
minimize the probability that something bad happens.

This is crucial, because it turns out that there seems to often be a "sweet
spot" where you are taking on a manageable amount of risk, you sometimes fail
(but not too often), and you are succeeding enough to cover that risk and reap a
greater reward. Too much risk and we say you're simply gambling; but too little
risk and you have an even worse problem. Many people are at sub-par jobs waiting
for a promotion and pay raise that's years overdue, because they're terrified of
what should happen if they look for a new job -- what if they become jobless?
they worry.

You can see this especially in backgammon games. Go and watch a new player play
against an intermediate player in backgammon. You will notice this striking
fact: that the new player seems to be very lucky in the first half of the game,
seems to have always the right dice for a useful move, and makes much better
progress -- the intermediate player seems to be forced into many more mistakes.
But then, halfway through the game, the luck reverses. One of his pawns becomes
exposed, gets knocked back to the beginning, and is stuck, preventing him from
having further turns. The intermediate player makes up all of the "lost time"
and then some more during this moment, or perhaps they just end the game early
by use of the doubling cube, if they don't think they can achieve a gammon.

Unsafe moves are necessary for building position, for creating options, in
backgammon. If you wildly overestimate costs by not ever considering them, then
you will simply never work up that courage needed to tell someone who you are
madly infatuated with, no matter how low the actual cost is.

## Bias

I'm not really sure what to call it, but we need a term for these fallacies
which emerge in the biases people show today. People overestimate the
probabilities for things which are easy to imagine and underestimate the
probabilities of things which are hard to imagine; which means that people
assume that their life experiences are more probable than they really are, and
that other experiences are highly improbable. You simply do not register the
probability of the car crash until you know someone who has been in one.

People also assume that the universe will be less extreme than it is due to some
sort of cosmic justice. The well-known Gambler's fallacy, for example, says "I
keep losing at this game so clearly I'm about to start winning." What I want to
say is that there is a broad failure of honesty here which must be also
considered, an abdication of clear-thought and an acceptance of bias. Let me
give a very clear example of what I mean:

If I say that women got 5 points greater on an IQ test than men did, people will
assume that *all* women are more intelligent than *all* men even if the standard
deviation is +/- 10 or +/- 15, so that this is not too substantial when compared
to the spread.  Moreover people assume that such averages are indicative of the
exceptional: it could be possible for example that women have an IQ 10 points
higher than men, but that the top 10% of the IQ range is disproportionately
male. How on earth would this happen? Because the bottom 50% would also be
disproportionately male: women would "cluster together" at a higher average IQ
while men would have more "spread" at their lower average IQ.

The point is that you probably didn't hear that, because it's such a tense
subject of gender politics. Actually a guy named Lawrence Summers ultimately
resigned the Presidency of Harvard for a very similar reason.

The point is that there is a fallacy here. Imagine that someone tells you that
in their opinion *both* of the following are true: (1) "the smartest people in
the world are disproportionately men", and (2) "women are in general much
smarter than men." You *probably* look at (1) and (2) and see an inconsistency.
The point is that there is *no logical inconsistency* in the above two
statements. Even if you could prove that the smartest folks in the world are
men, it would not tell you that men are generally more intelligent than women.
The whole population does not have to reflect such a sample. And if you thought
clearly about it, you can trivially see that there is no logical arrow from one
to the other -- but we mask these issues in emotional biases and then fail to
perceive the whole.



If it sounds like
it would be logically inconsistent to say both that "women are smarter than men" and "the smartest people are more male than female,"